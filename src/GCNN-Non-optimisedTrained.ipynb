{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea619ca5",
   "metadata": {},
   "source": [
    "#### This jupyter contains out initial implementation of the GCNN artchitecture. This solution is slow for three reasons:\n",
    "1. Conv2D is called way more than needed, the solution does not use vector stacking\n",
    "2. Does not use a filther bank, which computes transformations on the go\n",
    "3. Does not use batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae557072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 1 - Training: 100%|██████████| 7/7 [00:00<00:00, 17.18it/s]\n",
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: CNN | Train Acc: 0.2750 | Test Acc: 0.2125 | Val Acc: 0.2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 2 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.64it/s]\n",
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: CNN | Train Acc: 0.2325 | Test Acc: 0.2250 | Val Acc: 0.2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 3 - Training: 100%|██████████| 7/7 [00:00<00:00, 16.90it/s]\n",
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: CNN | Train Acc: 0.3450 | Test Acc: 0.3875 | Val Acc: 0.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 4 - Training: 100%|██████████| 7/7 [00:00<00:00, 16.71it/s]\n",
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: CNN | Train Acc: 0.5500 | Test Acc: 0.3250 | Val Acc: 0.3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 5 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.57it/s]\n",
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: CNN | Train Acc: 0.4800 | Test Acc: 0.3750 | Val Acc: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 6 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.47it/s]\n",
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: CNN | Train Acc: 0.4825 | Test Acc: 0.3000 | Val Acc: 0.4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 7 - Training: 100%|██████████| 7/7 [00:00<00:00, 17.75it/s]\n",
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: CNN | Train Acc: 0.5950 | Test Acc: 0.2250 | Val Acc: 0.3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 8 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.39it/s]\n",
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: CNN | Train Acc: 0.5700 | Test Acc: 0.4125 | Val Acc: 0.4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 9 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.29it/s]\n",
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: CNN | Train Acc: 0.6900 | Test Acc: 0.4375 | Val Acc: 0.5200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 10 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.39it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: CNN | Train Acc: 0.6750 | Test Acc: 0.4375 | Val Acc: 0.4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 11 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.20it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: CNN | Train Acc: 0.6750 | Test Acc: 0.4875 | Val Acc: 0.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 12 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.73it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: CNN | Train Acc: 0.6500 | Test Acc: 0.5500 | Val Acc: 0.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 13 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.65it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: CNN | Train Acc: 0.6975 | Test Acc: 0.4500 | Val Acc: 0.6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 14 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.55it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: CNN | Train Acc: 0.7300 | Test Acc: 0.5000 | Val Acc: 0.4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 15 - Training: 100%|██████████| 7/7 [00:00<00:00, 17.17it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: CNN | Train Acc: 0.8075 | Test Acc: 0.6000 | Val Acc: 0.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 1 - Training: 100%|██████████| 7/7 [19:23<00:00, 166.23s/it]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: GCNN | Train Acc: 0.2400 | Test Acc: 0.3000 | Val Acc: 0.2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 2 - Training: 100%|██████████| 7/7 [19:02<00:00, 163.26s/it]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: GCNN | Train Acc: 0.2750 | Test Acc: 0.3625 | Val Acc: 0.2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 3 - Training: 100%|██████████| 7/7 [18:54<00:00, 162.07s/it]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: GCNN | Train Acc: 0.2825 | Test Acc: 0.3625 | Val Acc: 0.2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 4 - Training: 100%|██████████| 7/7 [19:06<00:00, 163.72s/it]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: GCNN | Train Acc: 0.2825 | Test Acc: 0.3625 | Val Acc: 0.2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 5 - Training: 100%|██████████| 7/7 [18:45<00:00, 160.85s/it]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: GCNN | Train Acc: 0.3575 | Test Acc: 0.5875 | Val Acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 6 - Training: 100%|██████████| 7/7 [18:55<00:00, 162.16s/it]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: GCNN | Train Acc: 0.3525 | Test Acc: 0.5750 | Val Acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 7 - Training: 100%|██████████| 7/7 [18:51<00:00, 161.62s/it]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: GCNN | Train Acc: 0.4375 | Test Acc: 0.5375 | Val Acc: 0.3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 8 - Training: 100%|██████████| 7/7 [18:37<00:00, 159.63s/it]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: GCNN | Train Acc: 0.5400 | Test Acc: 0.6375 | Val Acc: 0.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 9 - Training: 100%|██████████| 7/7 [18:28<00:00, 158.35s/it]\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: GCNN | Train Acc: 0.5200 | Test Acc: 0.6250 | Val Acc: 0.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 10 - Training: 100%|██████████| 7/7 [18:48<00:00, 161.28s/it]\n",
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: GCNN | Train Acc: 0.5550 | Test Acc: 0.6125 | Val Acc: 0.5200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 11 - Training: 100%|██████████| 7/7 [18:56<00:00, 162.29s/it]\n",
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: GCNN | Train Acc: 0.5575 | Test Acc: 0.6500 | Val Acc: 0.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 12 - Training: 100%|██████████| 7/7 [18:35<00:00, 159.40s/it]\n",
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: GCNN | Train Acc: 0.6025 | Test Acc: 0.6125 | Val Acc: 0.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 13 - Training: 100%|██████████| 7/7 [18:48<00:00, 161.27s/it]\n",
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: GCNN | Train Acc: 0.6075 | Test Acc: 0.6000 | Val Acc: 0.6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 14 - Training: 100%|██████████| 7/7 [19:00<00:00, 162.91s/it]\n",
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: GCNN | Train Acc: 0.5925 | Test Acc: 0.6375 | Val Acc: 0.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[GCNN] Epoch 15 - Training: 100%|██████████| 7/7 [19:02<00:00, 163.28s/it]\n",
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: GCNN | Train Acc: 0.6225 | Test Acc: 0.6625 | Val Acc: 0.5400\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.nn import AdaptiveAvgPool3d\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(2)\n",
    "np.random.seed(2)\n",
    "random.seed(2)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data Loader\n",
    "\n",
    "def get_mnist_loaders(data_dir=\"./data\", batch_size=64, n_train=400, n_test=80, n_val=50, digits=(0, 1, 2, 3, 4)):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    rotation_aug = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomRotation((0, 360)),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    trainset = datasets.MNIST(data_dir, train=True, download=True, transform=transform)\n",
    "    testset = datasets.MNIST(data_dir, train=False, download=True, transform=rotation_aug)\n",
    "\n",
    "    # Filter datasets to only include specified digits\n",
    "    train_indices = [i for i, target in enumerate(trainset.targets) if target in digits]\n",
    "    test_indices = [i for i, target in enumerate(testset.targets) if target in digits]\n",
    "\n",
    "    train_subset = Subset(trainset, train_indices[:min(n_train, len(train_indices))])\n",
    "    test_subset = Subset(testset, test_indices[:min(n_test, len(test_indices))])\n",
    "    val_subset = Subset(testset, test_indices[min(n_test, len(test_indices)):min(n_test + n_val, len(test_indices))])\n",
    "\n",
    "    digit_map = {digit: i for i, digit in enumerate(digits)}\n",
    "\n",
    "    # Fix the labels in the subsets directly\n",
    "    def map_targets(subset):\n",
    "        subset.dataset.targets[subset.indices] = torch.tensor([\n",
    "            digit_map[subset.dataset.targets[i].item()] for i in subset.indices\n",
    "        ])\n",
    "\n",
    "    map_targets(train_subset)\n",
    "    map_targets(test_subset)\n",
    "    map_targets(val_subset)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, val_loader\n",
    "\n",
    "train_loader, test_loader, val_loader = get_mnist_loaders(digits=(0, 1, 7, 8))\n",
    "\n",
    "\n",
    "\n",
    "# Group Definition\n",
    "class CyclicGroup:\n",
    "    def __init__(self, order: int):\n",
    "        self.n_int = order  # Group order for C_n (discrete cyclic group)\n",
    "\n",
    "    def elements(self, device=None):\n",
    "        # Discrete rotation group elements as angles (in radians)\n",
    "        # These represent H in G = R^2 ⋉ H\n",
    "        angles = [2 * np.pi * k / self.n_int for k in range(self.n_int)]\n",
    "        return torch.tensor(angles, dtype=torch.float32, device=device)\n",
    "\n",
    "    def product(self, h, h_prime):\n",
    "        # Group product: h ⋅ h'\n",
    "        return torch.remainder(h + h_prime, 2 * np.pi)\n",
    "\n",
    "    def inverse(self, h):\n",
    "        # Group inverse: h⁻¹\n",
    "        return torch.remainder(-h, 2 * np.pi)\n",
    "\n",
    "    def left_regular_representation(self, h, x):\n",
    "        # Applies the left regular representation matrix to x ∈ ℝ²\n",
    "        # Corresponds to L^H_h in the theory\n",
    "        return torch.matmul(self.matrix_representation(h), x)\n",
    "\n",
    "    def matrix_representation(self, h):\n",
    "        # Standard SO(2) matrix representation\n",
    "        return torch.tensor([\n",
    "            [torch.cos(h), -torch.sin(h)],\n",
    "            [torch.sin(h), torch.cos(h)]\n",
    "        ], device=h.device)\n",
    "\n",
    "\n",
    "# Rotation of 2D kernels (L^H_h(k))\n",
    "def rotate_kernel(kernel_2d, group, angle_rad):\n",
    "    # Implements L^H_h(k): transform kernel by group element h\n",
    "    # i.e., rotate the kernel in the spatial domain (inverse action)\n",
    "\n",
    "    # Create normalized grid\n",
    "    y, x = torch.meshgrid(torch.linspace(-1, 1, kernel_2d.shape[0], device=kernel_2d.device),\n",
    "                          torch.linspace(-1, 1, kernel_2d.shape[1], device=kernel_2d.device),\n",
    "                          indexing='ij')\n",
    "    grid = torch.stack([x, y], dim=-1).view(-1, 2)\n",
    "\n",
    "    # Apply inverse transformation (h⁻¹ ▷ y)\n",
    "    angle_inv = group.inverse(angle_rad)\n",
    "    rot_grid_flat = torch.stack([group.left_regular_representation(angle_inv, coord) for coord in grid], dim=0)\n",
    "    rot_grid = rot_grid_flat.view(kernel_2d.shape[0], kernel_2d.shape[1], 2).unsqueeze(0)\n",
    "\n",
    "    # Grid sample (resample the kernel at transformed coordinates)\n",
    "    kernel = kernel_2d.unsqueeze(0).unsqueeze(0)\n",
    "    rotated = F.grid_sample(kernel, rot_grid, align_corners=True, mode='bilinear', padding_mode='zeros')\n",
    "\n",
    "    return rotated.squeeze()  # Returns k(h⁻¹ ▷ y)\n",
    "\n",
    "\n",
    "# Lifting Layer: ℝ² → G\n",
    "class LiftingConvolution(nn.Module):\n",
    "    def __init__(self, group, in_channels, out_channels, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.group = group\n",
    "        self.base_kernel = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size, kernel_size))\n",
    "        nn.init.kaiming_uniform_(self.base_kernel, a=np.sqrt(5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: x ∈ ℝ² (image)\n",
    "        # Output: f_out ∈ G → ℝ^C (stack of rotated conv results)\n",
    "\n",
    "        group_elements = self.group.elements(device=x.device)\n",
    "        outputs = []\n",
    "\n",
    "        for angle in group_elements:\n",
    "            rotated_kernel = torch.zeros_like(self.base_kernel)\n",
    "            for oc in range(self.base_kernel.shape[0]):\n",
    "                for ic in range(self.base_kernel.shape[1]):\n",
    "                    # Apply L^H_h to kernel\n",
    "                    rotated_kernel[oc, ic] = rotate_kernel(self.base_kernel[oc, ic], self.group, angle)\n",
    "\n",
    "            # Standard 2D convolution (L^ℝ²_x)\n",
    "            conv_out = F.conv2d(x, rotated_kernel, padding=self.padding)\n",
    "            outputs.append(conv_out.unsqueeze(2))  # Append G-dimension\n",
    "\n",
    "        return torch.cat(outputs, dim=2)  # Shape: (B, C_out, G, H, W)\n",
    "\n",
    "# Group Convolution Layer: G → G\n",
    "class GroupConvolution(nn.Module):\n",
    "    def __init__(self, group, in_channels, out_channels, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.group = group\n",
    "        self.G = group.n_int\n",
    "\n",
    "        # Kernels indexed by group elements: k[g_out][g_in]\n",
    "        self.base_kernel = nn.Parameter(torch.randn(\n",
    "            self.G, self.G, out_channels, in_channels, kernel_size, kernel_size\n",
    "        ))\n",
    "        nn.init.kaiming_uniform_(self.base_kernel, a=np.sqrt(5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: f_in ∈ G → ℝ^C_in (B, C_in, G, H, W)\n",
    "        # Output: f_out ∈ G → ℝ^C_out (B, C_out, G, H, W)\n",
    "\n",
    "        group_elements = self.group.elements(device=x.device)\n",
    "        output = torch.zeros(x.shape[0], self.base_kernel.shape[2], self.G, x.shape[3], x.shape[4], device=x.device)\n",
    "\n",
    "        for g_out_idx, g_out in enumerate(group_elements):\n",
    "            for g_in_idx, g_in in enumerate(group_elements):\n",
    "                # Relative transformation h_rel = g_out⁻¹ * g_in\n",
    "                h_rel = self.group.product(self.group.inverse(g_out), g_in)\n",
    "\n",
    "                for oc in range(self.base_kernel.shape[2]):\n",
    "                    for ic in range(self.base_kernel.shape[3]):\n",
    "                        base_k = self.base_kernel[g_out_idx, g_in_idx, oc, ic]\n",
    "                        # Apply L^H_{h_rel}(k)\n",
    "                        rot_k = rotate_kernel(base_k, self.group, h_rel).unsqueeze(0).unsqueeze(0)\n",
    "                        x_in = x[:, ic, g_in_idx].unsqueeze(1)\n",
    "                        output[:, oc, g_out_idx] += F.conv2d(x_in, rot_k, padding=self.padding).squeeze(1)\n",
    "\n",
    "        return output  # G → ℝ^C_out\n",
    "\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, num_hidden, hidden_channels):\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2  # e.g., for kernel_size=5, padding=2\n",
    "        self.first_conv = nn.Conv2d(in_channels, hidden_channels, kernel_size, padding=padding)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size, padding=padding) for _ in range(num_hidden)\n",
    "        ])\n",
    "        self.final_linear = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_conv(x)\n",
    "        x = F.layer_norm(x, x.shape[-3:])\n",
    "        x = F.relu(x)\n",
    "        for conv in self.convs:\n",
    "            x = conv(x)\n",
    "            x = F.layer_norm(x, x.shape[-3:])\n",
    "            x = F.relu(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).squeeze()\n",
    "        return self.final_linear(x)\n",
    "\n",
    "\n",
    "# Group Equivariant CNN Architecture\n",
    "class GroupEquivariantCNN(nn.Module):\n",
    "    def __init__(self, group, in_channels, out_channels, kernel_size, num_hidden, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lifting_conv = LiftingConvolution(group, in_channels, hidden_channels, kernel_size, padding=kernel_size//2)\n",
    "        self.gconvs = nn.ModuleList([\n",
    "            GroupConvolution(group, hidden_channels, hidden_channels, kernel_size, padding=kernel_size//2)\n",
    "            for _ in range(num_hidden)\n",
    "        ])\n",
    "        # Projection from G → ℝ by global average over G, H, W\n",
    "        self.projection_layer = AdaptiveAvgPool3d(1)\n",
    "        self.final_linear = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Step 1: Lift input image from ℝ² to G (lifting convolution)\n",
    "        x = self.lifting_conv(x)\n",
    "        x = F.layer_norm(x, x.shape[-4:])\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Step 2: Apply group convolutions G → G\n",
    "        for gconv in self.gconvs:\n",
    "            x = gconv(x)\n",
    "            x = F.layer_norm(x, x.shape[-4:])\n",
    "            x = F.relu(x)\n",
    "\n",
    "        # Step 3: Pool over all dimensions (incl. group axis) and classify\n",
    "        x = self.projection_layer(x).squeeze()\n",
    "        return self.final_linear(x)\n",
    "\n",
    "\n",
    "# Training utilities\n",
    "\n",
    "def train_model(model_name, model_hparams, optimizer_name, optimizer_hparams):\n",
    "    model_class = GroupEquivariantCNN if model_name == \"GCNN\" else CNN\n",
    "    model = model_class(**model_hparams).to(device)\n",
    "\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), **optimizer_hparams)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    for epoch in range(1, 16):\n",
    "        model.train()\n",
    "        correct, total, loss_sum = 0, 0, 0\n",
    "        for x, y in tqdm(train_loader, desc=f\"[{model_name}] Epoch {epoch} - Training\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item() * x.size(0)\n",
    "            correct += (out.argmax(1) == y).sum().item()\n",
    "            total += x.size(0)\n",
    "        train_loss = loss_sum / total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        model.eval()\n",
    "        def evaluate(loader, desc):\n",
    "            correct, total, loss_sum = 0, 0, 0\n",
    "            for x, y in tqdm(loader, desc=desc, leave=False):\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                out = model(x)\n",
    "                loss = criterion(out, y)\n",
    "                loss_sum += loss.item() * x.size(0)\n",
    "                correct += (out.argmax(1) == y).sum().item()\n",
    "                total += x.size(0)\n",
    "            return loss_sum / total, correct / total\n",
    "\n",
    "        test_loss, test_acc = evaluate(test_loader, f\"[{model_name}] Epoch {epoch} - Test\")\n",
    "        val_loss, val_acc = evaluate(val_loader, f\"[{model_name}] Epoch {epoch} - Validation\")\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}: {model_name} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "cnn_model, cnn_results = train_model(\n",
    "    model_name=\"CNN\",\n",
    "    model_hparams={\"in_channels\": 1, \"out_channels\": 5, \"kernel_size\": 5, \"num_hidden\": 3, \"hidden_channels\": 16},\n",
    "    optimizer_name=\"Adam\",\n",
    "    optimizer_hparams={\"lr\": 0.001, \"weight_decay\": 1e-5},\n",
    ")\n",
    "\n",
    "\n",
    "# Model Training Calls\n",
    "gcnn_model, gcnn_results = train_model(\n",
    "    model_name=\"GCNN\",\n",
    "    model_hparams={\"in_channels\": 1, \"out_channels\": 5, \"kernel_size\": 5, \"num_hidden\": 3  ,\n",
    "                   \"hidden_channels\": 16, \"group\": CyclicGroup(order=4)},\n",
    "    optimizer_name=\"Adam\",\n",
    "    optimizer_hparams={\"lr\": 0.001, \"weight_decay\": 1e-5},\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0eb3a2",
   "metadata": {},
   "source": [
    "[CNN] Epoch 1 - Training: 100%|██████████| 7/7 [00:00<00:00, 17.18it/s]\n",
    "                                                                 \n",
    "Epoch 1: CNN | Train Acc: 0.2750 | Test Acc: 0.2125 | Val Acc: 0.2400\n",
    "[CNN] Epoch 2 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.64it/s]\n",
    "                                                                 \n",
    "Epoch 2: CNN | Train Acc: 0.2325 | Test Acc: 0.2250 | Val Acc: 0.2400\n",
    "[CNN] Epoch 3 - Training: 100%|██████████| 7/7 [00:00<00:00, 16.90it/s]\n",
    "                                                                 \n",
    "Epoch 3: CNN | Train Acc: 0.3450 | Test Acc: 0.3875 | Val Acc: 0.5400\n",
    "[CNN] Epoch 4 - Training: 100%|██████████| 7/7 [00:00<00:00, 16.71it/s]\n",
    "                                                                 \n",
    "Epoch 4: CNN | Train Acc: 0.5500 | Test Acc: 0.3250 | Val Acc: 0.3400\n",
    "[CNN] Epoch 5 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.57it/s]\n",
    "                                                                 \n",
    "Epoch 5: CNN | Train Acc: 0.4800 | Test Acc: 0.3750 | Val Acc: 0.4000\n",
    "[CNN] Epoch 6 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.47it/s]\n",
    "                                                                 \n",
    "Epoch 6: CNN | Train Acc: 0.4825 | Test Acc: 0.3000 | Val Acc: 0.4600\n",
    "[CNN] Epoch 7 - Training: 100%|██████████| 7/7 [00:00<00:00, 17.75it/s]\n",
    "                                                                 \n",
    "Epoch 7: CNN | Train Acc: 0.5950 | Test Acc: 0.2250 | Val Acc: 0.3200\n",
    "[CNN] Epoch 8 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.39it/s]\n",
    "                                                                 \n",
    "Epoch 8: CNN | Train Acc: 0.5700 | Test Acc: 0.4125 | Val Acc: 0.4200\n",
    "[CNN] Epoch 9 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.29it/s]\n",
    "                                                                 \n",
    "Epoch 9: CNN | Train Acc: 0.6900 | Test Acc: 0.4375 | Val Acc: 0.5200\n",
    "[CNN] Epoch 10 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.39it/s]\n",
    "                                                                  \n",
    "Epoch 10: CNN | Train Acc: 0.6750 | Test Acc: 0.4375 | Val Acc: 0.4400\n",
    "[CNN] Epoch 11 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.20it/s]\n",
    "                                                                  \n",
    "Epoch 11: CNN | Train Acc: 0.6750 | Test Acc: 0.4875 | Val Acc: 0.5400\n",
    "[CNN] Epoch 12 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.73it/s]\n",
    "                                                                  \n",
    "Epoch 12: CNN | Train Acc: 0.6500 | Test Acc: 0.5500 | Val Acc: 0.7000\n",
    "[CNN] Epoch 13 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.65it/s]\n",
    "                                                                  \n",
    "Epoch 13: CNN | Train Acc: 0.6975 | Test Acc: 0.4500 | Val Acc: 0.6400\n",
    "[CNN] Epoch 14 - Training: 100%|██████████| 7/7 [00:00<00:00, 18.55it/s]\n",
    "                                                                  \n",
    "Epoch 14: CNN | Train Acc: 0.7300 | Test Acc: 0.5000 | Val Acc: 0.4800\n",
    "[CNN] Epoch 15 - Training: 100%|██████████| 7/7 [00:00<00:00, 17.17it/s]\n",
    "                                                                  \n",
    "**Epoch 15: CNN | Train Acc: 0.8075 | Test Acc: 0.6000 | Val Acc: 0.5600**\n",
    "\n",
    "\n",
    "[GCNN] Epoch 1 - Training: 100%|██████████| 7/7 [19:23<00:00, 166.23s/it]\n",
    "                                                                          \n",
    "Epoch 1: GCNN | Train Acc: 0.2400 | Test Acc: 0.3000 | Val Acc: 0.2600\n",
    "[GCNN] Epoch 2 - Training: 100%|██████████| 7/7 [19:02<00:00, 163.26s/it]\n",
    "                                                                          \n",
    "Epoch 2: GCNN | Train Acc: 0.2750 | Test Acc: 0.3625 | Val Acc: 0.2800\n",
    "[GCNN] Epoch 3 - Training: 100%|██████████| 7/7 [18:54<00:00, 162.07s/it]\n",
    "                                                                          \n",
    "Epoch 3: GCNN | Train Acc: 0.2825 | Test Acc: 0.3625 | Val Acc: 0.2800\n",
    "[GCNN] Epoch 4 - Training: 100%|██████████| 7/7 [19:06<00:00, 163.72s/it]\n",
    "                                                                          \n",
    "Epoch 4: GCNN | Train Acc: 0.2825 | Test Acc: 0.3625 | Val Acc: 0.2800\n",
    "[GCNN] Epoch 5 - Training: 100%|██████████| 7/7 [18:45<00:00, 160.85s/it]\n",
    "                                                                          \n",
    "Epoch 5: GCNN | Train Acc: 0.3575 | Test Acc: 0.5875 | Val Acc: 0.5000\n",
    "[GCNN] Epoch 6 - Training: 100%|██████████| 7/7 [18:55<00:00, 162.16s/it]\n",
    "                                                                          \n",
    "Epoch 6: GCNN | Train Acc: 0.3525 | Test Acc: 0.5750 | Val Acc: 0.5000\n",
    "[GCNN] Epoch 7 - Training: 100%|██████████| 7/7 [18:51<00:00, 161.62s/it]\n",
    "                                                                          \n",
    "Epoch 7: GCNN | Train Acc: 0.4375 | Test Acc: 0.5375 | Val Acc: 0.3800\n",
    "[GCNN] Epoch 8 - Training: 100%|██████████| 7/7 [18:37<00:00, 159.63s/it]\n",
    "                                                                          \n",
    "Epoch 8: GCNN | Train Acc: 0.5400 | Test Acc: 0.6375 | Val Acc: 0.5400\n",
    "[GCNN] Epoch 9 - Training: 100%|██████████| 7/7 [18:28<00:00, 158.35s/it]\n",
    "                                                                          \n",
    "Epoch 9: GCNN | Train Acc: 0.5200 | Test Acc: 0.6250 | Val Acc: 0.5600\n",
    "[GCNN] Epoch 10 - Training: 100%|██████████| 7/7 [18:48<00:00, 161.28s/it]\n",
    "                                                                           \n",
    "Epoch 10: GCNN | Train Acc: 0.5550 | Test Acc: 0.6125 | Val Acc: 0.5200\n",
    "[GCNN] Epoch 11 - Training: 100%|██████████| 7/7 [18:56<00:00, 162.29s/it]\n",
    "                                                                           \n",
    "Epoch 11: GCNN | Train Acc: 0.5575 | Test Acc: 0.6500 | Val Acc: 0.5800\n",
    "[GCNN] Epoch 12 - Training: 100%|██████████| 7/7 [18:35<00:00, 159.40s/it]\n",
    "                                                                           \n",
    "Epoch 12: GCNN | Train Acc: 0.6025 | Test Acc: 0.6125 | Val Acc: 0.5600\n",
    "[GCNN] Epoch 13 - Training: 100%|██████████| 7/7 [18:48<00:00, 161.27s/it]\n",
    "                                                                           \n",
    "Epoch 13: GCNN | Train Acc: 0.6075 | Test Acc: 0.6000 | Val Acc: 0.6400\n",
    "[GCNN] Epoch 14 - Training: 100%|██████████| 7/7 [19:00<00:00, 162.91s/it]\n",
    "                                                                           \n",
    "Epoch 14: GCNN | Train Acc: 0.5925 | Test Acc: 0.6375 | Val Acc: 0.5800\n",
    "[GCNN] Epoch 15 - Training: 100%|██████████| 7/7 [19:02<00:00, 163.28s/it]\n",
    "\n",
    "\n",
    "**Epoch 15: GCNN | Train Acc: 0.6225 | Test Acc: 0.6625 | Val Acc: 0.5400**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
